<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Basic on Ben Snow's Blog</title><link>https://BenSnow6.github.io/categories/basic/</link><description>Recent content in Basic on Ben Snow's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><lastBuildDate>Wed, 05 Oct 2022 08:06:25 +0600</lastBuildDate><atom:link href="https://BenSnow6.github.io/categories/basic/index.xml" rel="self" type="application/rss+xml"/><item><title>Serverless Machine Learning Module 0</title><link>https://BenSnow6.github.io/posts/serverlessml/lab-modules/lab-0/</link><pubDate>Wed, 05 Oct 2022 08:06:25 +0600</pubDate><guid>https://BenSnow6.github.io/posts/serverlessml/lab-modules/lab-0/</guid><description>05/10/2022
Intro This course aims to allow a data scientist to deploy machine learning and predictive services online without the use of a server. This is useful in creating powerful business applications to show the predictive effect of a machine learning model quickly and effectively.
Labs Pandas We started with a simple pandas introduction lab involving converting to datetime from a given date field. After, we looked at applying functions to a series within the dataframe with a few different methods.</description></item><item><title>Serverless Machine Learning Module 1</title><link>https://BenSnow6.github.io/posts/serverlessml/lab-modules/lab-1/</link><pubDate>Wed, 05 Oct 2022 00:00:00 +0000</pubDate><guid>https://BenSnow6.github.io/posts/serverlessml/lab-modules/lab-1/</guid><description>05/10/2022
Lab 1 Serverless Machine Learning #machinelearning #course #hopsworks #serverless #gradio
Introduction Following on from Module 0 labs we are now going to look into deploying an actual machine learning product to the web! How exciting! :D
We are going to investigate the notorious Iris dataset and create several models to predict the variety of flower given a set of characteristics about flowers. This is a simple classification problem and we will use sklearn and pandas to create dataframes, split training and test sets, create a KNN model, evaluate this model, and then query the model!</description></item><item><title>Depth estimation project review</title><link>https://BenSnow6.github.io/posts/introduction/</link><pubDate>Mon, 27 Jun 2022 08:06:25 +0600</pubDate><guid>https://BenSnow6.github.io/posts/introduction/</guid><description>Introduction Today we&amp;rsquo;re going to take a look at a computer vision project on depth estimation and see how we can improve it. The goals of this investigation are twofold
Highlight the good and bad practices used in the project Apply MLOps techniques to serve a production model in the cloud A few of the techniques to be included are the following: Unit testing, CI/CD, cloud serving, monitoring, and model experimentation and evaluation.</description></item><item><title>Restructuring a project</title><link>https://BenSnow6.github.io/posts/restructuring/</link><pubDate>Mon, 27 Jun 2022 08:06:25 +0600</pubDate><guid>https://BenSnow6.github.io/posts/restructuring/</guid><description>Introduction Jumping right in, let&amp;rsquo;s start by creating a new folder on the desktop, a new conda environment, and activate that environment.
mkdir ~/Desktop/DepthEstimation conda create --name depth_env conda activate depth_env I will be using the CookieCutter Data Science template to create a new project structure. This is done with the following commands:
pip install cookiecutter cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science After filling in the CookieCutter template, we can navigate to the newly created project and start working on it.</description></item></channel></rss>